{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw6_3_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "curdzvVEcqNn"
      },
      "source": [
        "## 判斷是否使用Google colab執行\n",
        "若是，則從Google Drive掛載資料，Google colab專用 否則應設定 ROOT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T_LHI6nDcnoF",
        "outputId": "06213b8d-48f2-4448-fefe-6bc6be413645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print('IN_COLAB', IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    ROOT_DIR = '/content/drive/Shared drives/Straight A students/類神經網路/flowers'\n",
        "else:\n",
        "    ROOT_DIR = 'flowers'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IN_COLAB True\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oVaKal2pM2XT"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NUFZMmIfMiiY",
        "outputId": "f7c71175-dc68-4716-f3cf-06003342dcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "\"\"\" Deep Convolutional Generative Adversarial Network (DCGAN).\n",
        "\n",
        "Using deep convolutional generative adversarial networks (DCGAN) to generate\n",
        "digit images from a noise distribution.\n",
        "\n",
        "References:\n",
        "    - Unsupervised representation learning with deep convolutional generative\n",
        "    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n",
        "\n",
        "Links:\n",
        "    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n",
        "    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "Author: Aymeric Damien\n",
        "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cn8Jnp48SBMZ"
      },
      "source": [
        "## 設定參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEXKKDGkM7d6",
        "colab": {}
      },
      "source": [
        "# Training Params\n",
        "n_epoch = 50\n",
        "batch_size = 128\n",
        "image_size = 60\n",
        "\n",
        "# Network Params\n",
        "image_dim = image_size * image_size * 3\n",
        "gen_hidden_dim = 256\n",
        "disc_hidden_dim = 256\n",
        "noise_dim = 200 # Noise data points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BSoRpohxR_T9"
      },
      "source": [
        "## Read dataset\n",
        "參考自 https://www.tensorflow.org/tutorials/load_data/images#load_using_keraspreprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqMzFm5h-hdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no3vxtvP-i5_",
        "colab_type": "code",
        "outputId": "7b113584-76f7-4797-dede-a951cf8b82e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_gen = image_generator.flow_from_directory(directory=ROOT_DIR,\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(image_size, image_size))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4323 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCLApFwGaff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = len(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ29uP2v-nP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Q68lwu-tFg",
        "colab_type": "code",
        "outputId": "cdcfd27c-0249-4899-a7db-edea65291371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(image_batch.shape, label_batch.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 60, 60, 3) (128, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9qb4m2K-wJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(9):\n",
        "#     plt.subplot(3,3,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(image_batch[i], cmap=plt.cm.binary)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CeTj3mC2SEHJ"
      },
      "source": [
        "## 定義網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e_0R96QwM86X",
        "colab": {}
      },
      "source": [
        "# Generator Network\n",
        "# Input: Noise, Output: Image\n",
        "def generator(x, reuse=False):\n",
        "    with tf.variable_scope('Generator', reuse=reuse):\n",
        "        # TensorFlow Layers automatically create variables and calculate their\n",
        "        # shape, based on the input.\n",
        "        x = tf.layers.dense(x, units=6 * 6 * 128)\n",
        "        x = tf.nn.tanh(x)\n",
        "        # Reshape to a 4-D array of images: (batch, height, width, channels)\n",
        "        x = tf.reshape(x, shape=[-1, 6, 6, 128])\n",
        "        x = tf.layers.conv2d_transpose(x, 64, 4, strides=2)\n",
        "        x = tf.layers.conv2d_transpose(x, 6, 4, strides=2)\n",
        "        x = tf.layers.conv2d_transpose(x, 3, 2, strides=2)\n",
        "        # Apply sigmoid to clip values between 0 and 1\n",
        "        x = tf.nn.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Discriminator Network\n",
        "# Input: Image, Output: Prediction Real/Fake Image\n",
        "def discriminator(x, reuse=False):\n",
        "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
        "        # Typical convolutional neural network to classify images.\n",
        "        # 60*60\n",
        "        x = tf.layers.conv2d(x, 64, 5) # 56*56*64\n",
        "        x = tf.nn.tanh(x)\n",
        "        x = tf.layers.average_pooling2d(x, 2, 2) # 28*28*64\n",
        "        x = tf.layers.conv2d(x, 128, 5) # 24*24*128\n",
        "        x = tf.nn.tanh(x)\n",
        "        x = tf.layers.average_pooling2d(x, 2, 2) # 12*12*128\n",
        "        x = tf.layers.conv2d(x, 128, 5) # 8*8*128\n",
        "        x = tf.nn.tanh(x)\n",
        "        x = tf.layers.average_pooling2d(x, 2, 2) # 4*4*128\n",
        "        x = tf.contrib.layers.flatten(x) # 4*4*128=2048\n",
        "        x = tf.layers.dense(x, 1024)\n",
        "        x = tf.nn.tanh(x)\n",
        "        # Output 2 classes: Real and Fake images\n",
        "        x = tf.layers.dense(x, 2)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "znfcSC_mM-D1",
        "outputId": "7116f475-fd12-478a-826d-0878f178529f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "# Build Networks\n",
        "# Network Inputs\n",
        "noise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\n",
        "real_image_input = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3])\n",
        "\n",
        "# Build Generator Network\n",
        "gen_sample = generator(noise_input)\n",
        "print(gen_sample)\n",
        "\n",
        "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
        "disc_real = discriminator(real_image_input)\n",
        "print(disc_real)\n",
        "disc_fake = discriminator(gen_sample, reuse=True)\n",
        "disc_concat = tf.concat([disc_real, disc_fake], axis=0)\n",
        "\n",
        "# Build the stacked generator/discriminator\n",
        "stacked_gan = discriminator(gen_sample, reuse=True)\n",
        "\n",
        "# Build Targets (real or fake images)\n",
        "disc_target = tf.placeholder(tf.int32, shape=[None])\n",
        "gen_target = tf.placeholder(tf.int32, shape=[None])\n",
        "\n",
        "# Build Loss\n",
        "disc_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "    logits=disc_concat, labels=disc_target))\n",
        "gen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "    logits=stacked_gan, labels=gen_target))\n",
        "\n",
        "# Build Optimizers\n",
        "optimizer_gen = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "optimizer_disc = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "\n",
        "# Training Variables for each optimizer\n",
        "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
        "# need to precise for each one of them the specific variables to update.\n",
        "# Generator Network Variables\n",
        "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
        "# Discriminator Network Variables\n",
        "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n",
        "\n",
        "# Create training operations\n",
        "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
        "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-2bb6140e286f>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-2bb6140e286f>:9: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "Tensor(\"Generator/Sigmoid:0\", shape=(?, 60, 60, 3), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-13-2bb6140e286f>:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-2bb6140e286f>:25: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.AveragePooling2D instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "Tensor(\"Discriminator/dense_1/BiasAdd:0\", shape=(?, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gp3A0NeTSIAB"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yx-5FgyJNAGV",
        "colab": {}
      },
      "source": [
        "# Start training\n",
        "sess = tf.Session()\n",
        "\n",
        "# Run the initializer\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJsAV5K5Op06",
        "colab": {}
      },
      "source": [
        "# Noise input.\n",
        "eval_z = [np.random.uniform(-1., 1., size=[4, noise_dim]) for i in range(8)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KI_bzUEFE326",
        "colab": {}
      },
      "source": [
        "step = 0\n",
        "for batch_x, _ in train_data_gen:\n",
        "    epoch = step // STEPS_PER_EPOCH + 1\n",
        "    batch_in_epoch = step % STEPS_PER_EPOCH + 1\n",
        "\n",
        "    temp_batch_size = batch_x.shape[0]\n",
        "    # print(batch_x.shape)\n",
        "\n",
        "    batch_x = np.reshape(batch_x, newshape=[-1, image_size, image_size, 3])\n",
        "    # Generate noise to feed to the generator\n",
        "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
        "\n",
        "    # Prepare Targets (Real image: 1, Fake image: 0)\n",
        "    # The first half of data fed to the generator are real images,\n",
        "    # the other half are fake images (coming from the generator).\n",
        "    batch_disc_y = np.concatenate(\n",
        "        [np.ones([temp_batch_size]), np.zeros([batch_size])], axis=0)\n",
        "    # Generator tries to fool the discriminator, thus targets are 1.\n",
        "    batch_gen_y = np.ones([batch_size])\n",
        "\n",
        "    # print(batch_x.shape, z.shape, batch_disc_y.shape, batch_gen_y.shape)\n",
        "    # Training\n",
        "    feed_dict = {real_image_input: batch_x, noise_input: z,\n",
        "                    disc_target: batch_disc_y, gen_target: batch_gen_y}\n",
        "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
        "                            feed_dict=feed_dict)\n",
        "\n",
        "    print('epoch %i-%i: Generator Loss: %f, Discriminator Loss: %f' % (epoch, batch_in_epoch, gl, dl))\n",
        "\n",
        "    if batch_in_epoch == STEPS_PER_EPOCH and (epoch % 10 == 0 or epoch == 1):\n",
        "        # Generate images from noise, using the generator network.\n",
        "        fig = plt.figure()\n",
        "        f, a = plt.subplots(4, 8, figsize=(16, 8))\n",
        "        for i in range(8):\n",
        "            g = sess.run(gen_sample, feed_dict={noise_input: eval_z[i]})\n",
        "            for j in range(4):\n",
        "                # Generate image from noise. Extend to 3 channels for matplot figure.\n",
        "                img = g[j]\n",
        "                a[j][i].imshow(img)\n",
        "\n",
        "        f.show()\n",
        "        plt.draw()\n",
        "        f.savefig('/content/drive/My Drive/GAN/7/{}.jpg'.format(epoch))\n",
        "\n",
        "    step += 1\n",
        "    if step >= n_epoch * STEPS_PER_EPOCH:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kW96SjLnOr3k",
        "colab": {}
      },
      "source": [
        "# Generate images from noise, using the generator network.\n",
        "fig = plt.figure()\n",
        "f, a = plt.subplots(4, 8, figsize=(16, 8))\n",
        "for i in range(8):\n",
        "    g = sess.run(gen_sample, feed_dict={noise_input: eval_z[i]})\n",
        "    for j in range(4):\n",
        "        # Generate image from noise. Extend to 3 channels for matplot figure.\n",
        "        img = g[j]\n",
        "        a[j][i].imshow(img)\n",
        "\n",
        "f.show()\n",
        "plt.draw()\n",
        "f.savefig('/content/drive/My Drive/GAN/7/end.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}