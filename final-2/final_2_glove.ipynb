{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final-2_glove.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II5WS32flKFp",
        "colab_type": "text"
      },
      "source": [
        "# 本程式需要在Google Colab才能執行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1DWgB-7cScT",
        "colab_type": "text"
      },
      "source": [
        "## 下載GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShT1Zi67cYKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "728be62f-9a12-4ec1-9908-9f91d3e68218"
      },
      "source": [
        "!git clone https://github.com/stanfordnlp/GloVe.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GloVe'...\n",
            "remote: Enumerating objects: 436, done.\u001b[K\n",
            "remote: Total 436 (delta 0), reused 0 (delta 0), pack-reused 436\u001b[K\n",
            "Receiving objects: 100% (436/436), 179.83 KiB | 6.42 MiB/s, done.\n",
            "Resolving deltas: 100% (239/239), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYxMsaf1biQm",
        "colab_type": "text"
      },
      "source": [
        "## 下載IMDB資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CChKoaT8zqfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8fNvyFzsGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d351d76-e7fc-400f-fce6-7f832786cc79"
      },
      "source": [
        "if not os.path.exists('data/'):\n",
        "    os.makedirs('data/')\n",
        "\n",
        "url=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "filepath=\"data/aclImdb_v1.tar.gz\"\n",
        "if not os.path.isfile(filepath):\n",
        "    result=urllib.request.urlretrieve(url,filepath)\n",
        "    print('downloaded:',result)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloaded: ('data/aclImdb_v1.tar.gz', <http.client.HTTPMessage object at 0x7f5b8dfe0588>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_dFtwAw0iSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"data/aclImdb\"):\n",
        "    tfile = tarfile.open(\"data/aclImdb_v1.tar.gz\", 'r:gz')\n",
        "    result=tfile.extractall('data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7CYxJQK0-e_",
        "colab_type": "text"
      },
      "source": [
        "## 讀取檔案"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZJaETJc04yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def rm_tags(text):\n",
        "    re_tag = re.compile(r'<[^>]+>')\n",
        "    return re_tag.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSoXlIhg1AbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def read_files(filetype):\n",
        "    path = \"data/aclImdb/\"\n",
        "    file_list=[]\n",
        "\n",
        "    positive_path=path + filetype+\"/pos/\"\n",
        "    for f in os.listdir(positive_path):\n",
        "        file_list+=[positive_path+f]\n",
        "    \n",
        "    negative_path=path + filetype+\"/neg/\"\n",
        "    for f in os.listdir(negative_path):\n",
        "        file_list+=[negative_path+f]\n",
        "        \n",
        "    print('read',filetype, 'files:',len(file_list))\n",
        "       \n",
        "    all_labels = ([1] * 12500 + [0] * 12500) \n",
        "    \n",
        "    all_texts  = []\n",
        "    for fi in file_list:\n",
        "        with open(fi,encoding='utf8') as file_input:\n",
        "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
        "            \n",
        "    return all_labels,all_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YfTnqZw1B7u",
        "colab_type": "code",
        "outputId": "271ecde2-9d95-4d14-9118-8860a2cf11d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train,train_text=read_files(\"train\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read train files: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwBFlDN1Dqn",
        "colab_type": "code",
        "outputId": "a8bc1feb-cf8e-49b0-f1f5-eb6354239cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test,test_text=read_files(\"test\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read test files: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvzMFN42b_Jc",
        "colab_type": "text"
      },
      "source": [
        "## 將資料集文字移除標點符號，合併成一個list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYzEPTPM6Lf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "word_list = []\n",
        "\n",
        "for line in train_text + test_text:\n",
        "    line = line.lower()\n",
        "    line = re.sub(r\"([a-z]+)'[a-z]\\b\", '', line)\n",
        "    line = line.translate(table)\n",
        "    line = re.sub(r'  +', ' ', line)\n",
        "    line = line.strip().split(' ')\n",
        "    word_list.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYEwC2HEaT-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "37d78411-e0da-4fae-d0ef-d5b8189af66e"
      },
      "source": [
        "print(word_list[:100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'a', 'ripsnorting', 'oldfashioned', 'adventure', 'yarn', 'i', 'understand', 'that', 'by', 'political', 'standards', 'the', 'treatment', 'of', 'the', 'indians', 'was', 'unacceptable', 'but', 'this', 'moving', 'about', 'politics', 'about', 'action', 'dialogue', 'comradery', 'acting', 'direction', 'music', 'and', 'photography', 'and', 'marvelous', 'on', 'all', 'these', 'factors', 'grant', 'fairbanks', 'and', 'mclaglen', 'are', 'electric', 'together', 'and', 'jaffe', 'is', 'superb', 'this', 'is', 'the', 'ultimate', 'buddy', 'movie', 'great', 'little', 'thriller', 'i', 'was', 'expecting', 'some', 'type', 'of', 'silly', 'horror', 'movie', 'but', 'what', 'i', 'got', 'was', 'tight', 'short', 'thriller', 'that', 'waste', 'none', 'of', 'our', 'time', 'mostof', 'these', 'movies', 'we', 'have', 'to', 'get', 'into', 'the', 'back', 'characters', 'stories', 'so', 'we', 'will', 'either', 'feel']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Fy0OkmaXyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('GloVe/imdb', 'w', encoding='utf8') as f:\n",
        "    f.write(' '.join(word_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1bcjpkqcxwb",
        "colab_type": "text"
      },
      "source": [
        "## 寫入自訂demo.sh到GloVe資料夾\n",
        "https://github.com/stanfordnlp/GloVe/blob/master/demo.sh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoKOuPfDcZ_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demosh = \"\"\"\n",
        "#!/bin/bash\n",
        "set -e\n",
        "\n",
        "# Makes programs, downloads sample data, trains a GloVe model, and then evaluates it.\n",
        "# One optional argument can specify the language used for eval script: matlab, octave or [default] python\n",
        "\n",
        "make\n",
        "\n",
        "CORPUS=imdb\n",
        "VOCAB_FILE=imdb.txt\n",
        "COOCCURRENCE_FILE=cooccurrence.bin\n",
        "COOCCURRENCE_SHUF_FILE=cooccurrence.shuf.bin\n",
        "BUILDDIR=build\n",
        "SAVE_FILE=vectors-imdb\n",
        "VERBOSE=2\n",
        "MEMORY=4.0\n",
        "VOCAB_MIN_COUNT=5\n",
        "VECTOR_SIZE=50\n",
        "MAX_ITER=15\n",
        "WINDOW_SIZE=15\n",
        "BINARY=2\n",
        "NUM_THREADS=8\n",
        "X_MAX=10\n",
        "\n",
        "echo\n",
        "echo \"$ $BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\"\n",
        "$BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\n",
        "echo \"$ $BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\"\n",
        "$BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\n",
        "echo \"$ $BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\"\n",
        "$BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\n",
        "echo \"$ $BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\"\n",
        "$BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\n",
        "if [ \"$CORPUS\" = 'imdb' ]; then\n",
        "   if [ \"$1\" = 'matlab' ]; then\n",
        "       matlab -nodisplay -nodesktop -nojvm -nosplash < ./eval/matlab/read_and_evaluate.m 1>&2 \n",
        "   elif [ \"$1\" = 'octave' ]; then\n",
        "       octave < ./eval/octave/read_and_evaluate_octave.m 1>&2\n",
        "   else\n",
        "       echo \"$ python eval/python/evaluate.py --vocab_file $VOCAB_FILE --vectors_file $SAVE_FILE.txt\"\n",
        "       python eval/python/evaluate.py --vocab_file $VOCAB_FILE --vectors_file $SAVE_FILE.txt\n",
        "   fi\n",
        "fi\n",
        "\"\"\"\n",
        "with open('GloVe/demo-imdb.sh', 'w', encoding='utf8') as f:\n",
        "    f.write(demosh)\n",
        "os.chmod(\"GloVe/demo-imdb.sh\", 0o777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOkoCYaFdlcy",
        "colab_type": "text"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KTU82IwdrvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c749f77-e1d1-4dd9-991e-a3bad97d399d"
      },
      "source": [
        "!cd GloVe && ./demo-imdb.sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir -p build\n",
            "gcc src/glove.c -o build/glove -lm -pthread -Ofast -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/glove.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kglove_thread\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/glove.c:117:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kfread(&cr, sizeof(CREC), 1, fin)\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc src/shuffle.c -o build/shuffle -lm -pthread -Ofast -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kshuffle_merge\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:106:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "                 \u001b[01;35m\u001b[Kfread(&array[i], sizeof(CREC), 1, fid[j])\u001b[m\u001b[K;\n",
            "                 \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kshuffle_by_chunks\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:163:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kfread(&array[i], sizeof(CREC), 1, fin)\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc src/cooccur.c -o build/cooccur -lm -pthread -Ofast -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmerge_files\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:267:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:277:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:290:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc src/vocab_count.c -o build/vocab_count -lm -pthread -Ofast -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\n",
            "$ build/vocab_count -min-count 5 -verbose 2 < imdb > imdb.txt\n",
            "BUILDING VOCABULARY\n",
            "Processed 0 tokens.\u001b[11G100000 tokens.\u001b[11G200000 tokens.\u001b[11G300000 tokens.\u001b[11G400000 tokens.\u001b[11G500000 tokens.\u001b[11G600000 tokens.\u001b[11G700000 tokens.\u001b[11G800000 tokens.\u001b[11G900000 tokens.\u001b[11G1000000 tokens.\u001b[11G1100000 tokens.\u001b[11G1200000 tokens.\u001b[11G1300000 tokens.\u001b[11G1400000 tokens.\u001b[11G1500000 tokens.\u001b[11G1600000 tokens.\u001b[11G1700000 tokens.\u001b[11G1800000 tokens.\u001b[11G1900000 tokens.\u001b[11G2000000 tokens.\u001b[11G2100000 tokens.\u001b[11G2200000 tokens.\u001b[11G2300000 tokens.\u001b[11G2400000 tokens.\u001b[11G2500000 tokens.\u001b[11G2600000 tokens.\u001b[11G2700000 tokens.\u001b[11G2800000 tokens.\u001b[11G2900000 tokens.\u001b[11G3000000 tokens.\u001b[11G3100000 tokens.\u001b[11G3200000 tokens.\u001b[11G3300000 tokens.\u001b[11G3400000 tokens.\u001b[11G3500000 tokens.\u001b[11G3600000 tokens.\u001b[11G3700000 tokens.\u001b[11G3800000 tokens.\u001b[11G3900000 tokens.\u001b[11G4000000 tokens.\u001b[11G4100000 tokens.\u001b[11G4200000 tokens.\u001b[11G4300000 tokens.\u001b[11G4400000 tokens.\u001b[11G4500000 tokens.\u001b[11G4600000 tokens.\u001b[11G4700000 tokens.\u001b[11G4800000 tokens.\u001b[11G4900000 tokens.\u001b[11G5000000 tokens.\u001b[11G5100000 tokens.\u001b[11G5200000 tokens.\u001b[11G5300000 tokens.\u001b[11G5400000 tokens.\u001b[11G5500000 tokens.\u001b[11G5600000 tokens.\u001b[11G5700000 tokens.\u001b[11G5800000 tokens.\u001b[11G5900000 tokens.\u001b[11G6000000 tokens.\u001b[11G6100000 tokens.\u001b[11G6200000 tokens.\u001b[11G6300000 tokens.\u001b[11G6400000 tokens.\u001b[11G6500000 tokens.\u001b[11G6600000 tokens.\u001b[11G6700000 tokens.\u001b[11G6800000 tokens.\u001b[11G6900000 tokens.\u001b[11G7000000 tokens.\u001b[11G7100000 tokens.\u001b[11G7200000 tokens.\u001b[11G7300000 tokens.\u001b[11G7400000 tokens.\u001b[11G7500000 tokens.\u001b[11G7600000 tokens.\u001b[11G7700000 tokens.\u001b[11G7800000 tokens.\u001b[11G7900000 tokens.\u001b[11G8000000 tokens.\u001b[11G8100000 tokens.\u001b[11G8200000 tokens.\u001b[11G8300000 tokens.\u001b[11G8400000 tokens.\u001b[11G8500000 tokens.\u001b[11G8600000 tokens.\u001b[11G8700000 tokens.\u001b[11G8800000 tokens.\u001b[11G8900000 tokens.\u001b[11G9000000 tokens.\u001b[11G9100000 tokens.\u001b[11G9200000 tokens.\u001b[11G9300000 tokens.\u001b[11G9400000 tokens.\u001b[11G9500000 tokens.\u001b[11G9600000 tokens.\u001b[11G9700000 tokens.\u001b[11G9800000 tokens.\u001b[11G9900000 tokens.\u001b[11G10000000 tokens.\u001b[11G10100000 tokens.\u001b[11G10200000 tokens.\u001b[11G10300000 tokens.\u001b[11G10400000 tokens.\u001b[11G10500000 tokens.\u001b[11G10600000 tokens.\u001b[11G10700000 tokens.\u001b[11G10800000 tokens.\u001b[11G10900000 tokens.\u001b[11G11000000 tokens.\u001b[11G11100000 tokens.\u001b[0GProcessed 11120066 tokens.\n",
            "Counted 212797 unique words.\n",
            "Truncating vocabulary at min count 5.\n",
            "Using vocabulary of size 42572.\n",
            "\n",
            "$ build/cooccur -memory 4.0 -vocab-file imdb.txt -verbose 2 -window-size 15 < imdb > cooccurrence.bin\n",
            "COUNTING COOCCURRENCES\n",
            "window size: 15\n",
            "context: symmetric\n",
            "max product: 13752509\n",
            "overflow length: 38028356\n",
            "Reading vocab from file \"imdb.txt\"...loaded 42572 words.\n",
            "Building lookup table...table contains 80838643 elements.\n",
            "Processing token: 0\u001b[19G100000\u001b[19G200000\u001b[19G300000\u001b[19G400000\u001b[19G500000\u001b[19G600000\u001b[19G700000\u001b[19G800000\u001b[19G900000\u001b[19G1000000\u001b[19G1100000\u001b[19G1200000\u001b[19G1300000\u001b[19G1400000\u001b[19G1500000\u001b[19G1600000\u001b[19G1700000\u001b[19G1800000\u001b[19G1900000\u001b[19G2000000\u001b[19G2100000\u001b[19G2200000\u001b[19G2300000\u001b[19G2400000\u001b[19G2500000\u001b[19G2600000\u001b[19G2700000\u001b[19G2800000\u001b[19G2900000\u001b[19G3000000\u001b[19G3100000\u001b[19G3200000\u001b[19G3300000\u001b[19G3400000\u001b[19G3500000\u001b[19G3600000\u001b[19G3700000\u001b[19G3800000\u001b[19G3900000\u001b[19G4000000\u001b[19G4100000\u001b[19G4200000\u001b[19G4300000\u001b[19G4400000\u001b[19G4500000\u001b[19G4600000\u001b[19G4700000\u001b[19G4800000\u001b[19G4900000\u001b[19G5000000\u001b[19G5100000\u001b[19G5200000\u001b[19G5300000\u001b[19G5400000\u001b[19G5500000\u001b[19G5600000\u001b[19G5700000\u001b[19G5800000\u001b[19G5900000\u001b[19G6000000\u001b[19G6100000\u001b[19G6200000\u001b[19G6300000\u001b[19G6400000\u001b[19G6500000\u001b[19G6600000\u001b[19G6700000\u001b[19G6800000\u001b[19G6900000\u001b[19G7000000\u001b[19G7100000\u001b[19G7200000\u001b[19G7300000\u001b[19G7400000\u001b[19G7500000\u001b[19G7600000\u001b[19G7700000\u001b[19G7800000\u001b[19G7900000\u001b[19G8000000\u001b[19G8100000\u001b[19G8200000\u001b[19G8300000\u001b[19G8400000\u001b[19G8500000\u001b[19G8600000\u001b[19G8700000\u001b[19G8800000\u001b[19G8900000\u001b[19G9000000\u001b[19G9100000\u001b[19G9200000\u001b[19G9300000\u001b[19G9400000\u001b[19G9500000\u001b[19G9600000\u001b[19G9700000\u001b[19G9800000\u001b[19G9900000\u001b[19G10000000\u001b[19G10100000\u001b[19G10200000\u001b[19G10300000\u001b[19G10400000\u001b[19G10500000\u001b[19G10600000\u001b[19G10700000\u001b[19G10800000\u001b[19G10900000\u001b[19G11000000\u001b[19G11100000\u001b[0GProcessed 11120066 tokens.\n",
            "Writing cooccurrences to disk........2 files in total.\n",
            "Merging cooccurrence files: processed 0 lines.\u001b[39G100000 lines.\u001b[39G200000 lines.\u001b[39G300000 lines.\u001b[39G400000 lines.\u001b[39G500000 lines.\u001b[39G600000 lines.\u001b[39G700000 lines.\u001b[39G800000 lines.\u001b[39G900000 lines.\u001b[39G1000000 lines.\u001b[39G1100000 lines.\u001b[39G1200000 lines.\u001b[39G1300000 lines.\u001b[39G1400000 lines.\u001b[39G1500000 lines.\u001b[39G1600000 lines.\u001b[39G1700000 lines.\u001b[39G1800000 lines.\u001b[39G1900000 lines.\u001b[39G2000000 lines.\u001b[39G2100000 lines.\u001b[39G2200000 lines.\u001b[39G2300000 lines.\u001b[39G2400000 lines.\u001b[39G2500000 lines.\u001b[39G2600000 lines.\u001b[39G2700000 lines.\u001b[39G2800000 lines.\u001b[39G2900000 lines.\u001b[39G3000000 lines.\u001b[39G3100000 lines.\u001b[39G3200000 lines.\u001b[39G3300000 lines.\u001b[39G3400000 lines.\u001b[39G3500000 lines.\u001b[39G3600000 lines.\u001b[39G3700000 lines.\u001b[39G3800000 lines.\u001b[39G3900000 lines.\u001b[39G4000000 lines.\u001b[39G4100000 lines.\u001b[39G4200000 lines.\u001b[39G4300000 lines.\u001b[39G4400000 lines.\u001b[39G4500000 lines.\u001b[39G4600000 lines.\u001b[39G4700000 lines.\u001b[39G4800000 lines.\u001b[39G4900000 lines.\u001b[39G5000000 lines.\u001b[39G5100000 lines.\u001b[39G5200000 lines.\u001b[39G5300000 lines.\u001b[39G5400000 lines.\u001b[39G5500000 lines.\u001b[39G5600000 lines.\u001b[39G5700000 lines.\u001b[39G5800000 lines.\u001b[39G5900000 lines.\u001b[39G6000000 lines.\u001b[39G6100000 lines.\u001b[39G6200000 lines.\u001b[39G6300000 lines.\u001b[39G6400000 lines.\u001b[39G6500000 lines.\u001b[39G6600000 lines.\u001b[39G6700000 lines.\u001b[39G6800000 lines.\u001b[39G6900000 lines.\u001b[39G7000000 lines.\u001b[39G7100000 lines.\u001b[39G7200000 lines.\u001b[39G7300000 lines.\u001b[39G7400000 lines.\u001b[39G7500000 lines.\u001b[39G7600000 lines.\u001b[39G7700000 lines.\u001b[39G7800000 lines.\u001b[39G7900000 lines.\u001b[39G8000000 lines.\u001b[39G8100000 lines.\u001b[39G8200000 lines.\u001b[39G8300000 lines.\u001b[39G8400000 lines.\u001b[39G8500000 lines.\u001b[39G8600000 lines.\u001b[39G8700000 lines.\u001b[39G8800000 lines.\u001b[39G8900000 lines.\u001b[39G9000000 lines.\u001b[39G9100000 lines.\u001b[39G9200000 lines.\u001b[39G9300000 lines.\u001b[39G9400000 lines.\u001b[39G9500000 lines.\u001b[39G9600000 lines.\u001b[39G9700000 lines.\u001b[39G9800000 lines.\u001b[39G9900000 lines.\u001b[39G10000000 lines.\u001b[39G10100000 lines.\u001b[39G10200000 lines.\u001b[39G10300000 lines.\u001b[39G10400000 lines.\u001b[39G10500000 lines.\u001b[39G10600000 lines.\u001b[39G10700000 lines.\u001b[39G10800000 lines.\u001b[39G10900000 lines.\u001b[39G11000000 lines.\u001b[39G11100000 lines.\u001b[39G11200000 lines.\u001b[39G11300000 lines.\u001b[39G11400000 lines.\u001b[39G11500000 lines.\u001b[39G11600000 lines.\u001b[39G11700000 lines.\u001b[39G11800000 lines.\u001b[39G11900000 lines.\u001b[39G12000000 lines.\u001b[39G12100000 lines.\u001b[39G12200000 lines.\u001b[39G12300000 lines.\u001b[39G12400000 lines.\u001b[39G12500000 lines.\u001b[39G12600000 lines.\u001b[39G12700000 lines.\u001b[39G12800000 lines.\u001b[39G12900000 lines.\u001b[39G13000000 lines.\u001b[39G13100000 lines.\u001b[39G13200000 lines.\u001b[39G13300000 lines.\u001b[39G13400000 lines.\u001b[39G13500000 lines.\u001b[39G13600000 lines.\u001b[39G13700000 lines.\u001b[39G13800000 lines.\u001b[39G13900000 lines.\u001b[39G14000000 lines.\u001b[39G14100000 lines.\u001b[39G14200000 lines.\u001b[39G14300000 lines.\u001b[39G14400000 lines.\u001b[39G14500000 lines.\u001b[39G14600000 lines.\u001b[39G14700000 lines.\u001b[39G14800000 lines.\u001b[39G14900000 lines.\u001b[39G15000000 lines.\u001b[39G15100000 lines.\u001b[39G15200000 lines.\u001b[39G15300000 lines.\u001b[39G15400000 lines.\u001b[39G15500000 lines.\u001b[39G15600000 lines.\u001b[39G15700000 lines.\u001b[39G15800000 lines.\u001b[39G15900000 lines.\u001b[39G16000000 lines.\u001b[39G16100000 lines.\u001b[39G16200000 lines.\u001b[39G16300000 lines.\u001b[39G16400000 lines.\u001b[39G16500000 lines.\u001b[39G16600000 lines.\u001b[39G16700000 lines.\u001b[39G16800000 lines.\u001b[39G16900000 lines.\u001b[39G17000000 lines.\u001b[39G17100000 lines.\u001b[39G17200000 lines.\u001b[39G17300000 lines.\u001b[39G17400000 lines.\u001b[39G17500000 lines.\u001b[39G17600000 lines.\u001b[39G17700000 lines.\u001b[39G17800000 lines.\u001b[39G17900000 lines.\u001b[39G18000000 lines.\u001b[39G18100000 lines.\u001b[39G18200000 lines.\u001b[39G18300000 lines.\u001b[39G18400000 lines.\u001b[39G18500000 lines.\u001b[39G18600000 lines.\u001b[39G18700000 lines.\u001b[39G18800000 lines.\u001b[39G18900000 lines.\u001b[39G19000000 lines.\u001b[39G19100000 lines.\u001b[39G19200000 lines.\u001b[39G19300000 lines.\u001b[39G19400000 lines.\u001b[39G19500000 lines.\u001b[39G19600000 lines.\u001b[39G19700000 lines.\u001b[39G19800000 lines.\u001b[39G19900000 lines.\u001b[39G20000000 lines.\u001b[39G20100000 lines.\u001b[39G20200000 lines.\u001b[39G20300000 lines.\u001b[39G20400000 lines.\u001b[39G20500000 lines.\u001b[39G20600000 lines.\u001b[39G20700000 lines.\u001b[39G20800000 lines.\u001b[39G20900000 lines.\u001b[39G21000000 lines.\u001b[39G21100000 lines.\u001b[39G21200000 lines.\u001b[39G21300000 lines.\u001b[39G21400000 lines.\u001b[39G21500000 lines.\u001b[39G21600000 lines.\u001b[39G21700000 lines.\u001b[39G21800000 lines.\u001b[39G21900000 lines.\u001b[39G22000000 lines.\u001b[39G22100000 lines.\u001b[39G22200000 lines.\u001b[39G22300000 lines.\u001b[39G22400000 lines.\u001b[39G22500000 lines.\u001b[39G22600000 lines.\u001b[39G22700000 lines.\u001b[39G22800000 lines.\u001b[39G22900000 lines.\u001b[39G23000000 lines.\u001b[39G23100000 lines.\u001b[39G23200000 lines.\u001b[39G23300000 lines.\u001b[39G23400000 lines.\u001b[39G23500000 lines.\u001b[39G23600000 lines.\u001b[39G23700000 lines.\u001b[39G23800000 lines.\u001b[39G23900000 lines.\u001b[39G24000000 lines.\u001b[39G24100000 lines.\u001b[39G24200000 lines.\u001b[39G24300000 lines.\u001b[39G24400000 lines.\u001b[39G24500000 lines.\u001b[39G24600000 lines.\u001b[39G24700000 lines.\u001b[39G24800000 lines.\u001b[39G24900000 lines.\u001b[39G25000000 lines.\u001b[39G25100000 lines.\u001b[39G25200000 lines.\u001b[39G25300000 lines.\u001b[39G25400000 lines.\u001b[39G25500000 lines.\u001b[39G25600000 lines.\u001b[39G25700000 lines.\u001b[39G25800000 lines.\u001b[39G25900000 lines.\u001b[39G26000000 lines.\u001b[39G26100000 lines.\u001b[39G26200000 lines.\u001b[39G26300000 lines.\u001b[39G26400000 lines.\u001b[39G26500000 lines.\u001b[39G26600000 lines.\u001b[39G26700000 lines.\u001b[39G26800000 lines.\u001b[39G26900000 lines.\u001b[39G27000000 lines.\u001b[39G27100000 lines.\u001b[39G27200000 lines.\u001b[39G27300000 lines.\u001b[39G27400000 lines.\u001b[39G27500000 lines.\u001b[39G27600000 lines.\u001b[39G27700000 lines.\u001b[39G27800000 lines.\u001b[39G27900000 lines.\u001b[39G28000000 lines.\u001b[39G28100000 lines.\u001b[39G28200000 lines.\u001b[39G28300000 lines.\u001b[39G28400000 lines.\u001b[39G28500000 lines.\u001b[39G28600000 lines.\u001b[39G28700000 lines.\u001b[39G28800000 lines.\u001b[39G28900000 lines.\u001b[39G29000000 lines.\u001b[39G29100000 lines.\u001b[39G29200000 lines.\u001b[39G29300000 lines.\u001b[39G29400000 lines.\u001b[39G29500000 lines.\u001b[39G29600000 lines.\u001b[39G29700000 lines.\u001b[39G29800000 lines.\u001b[39G29900000 lines.\u001b[39G30000000 lines.\u001b[39G30100000 lines.\u001b[39G30200000 lines.\u001b[39G30300000 lines.\u001b[39G30400000 lines.\u001b[39G30500000 lines.\u001b[39G30600000 lines.\u001b[39G30700000 lines.\u001b[39G30800000 lines.\u001b[39G30900000 lines.\u001b[39G31000000 lines.\u001b[39G31100000 lines.\u001b[39G31200000 lines.\u001b[39G31300000 lines.\u001b[39G31400000 lines.\u001b[39G31500000 lines.\u001b[39G31600000 lines.\u001b[39G31700000 lines.\u001b[39G31800000 lines.\u001b[39G31900000 lines.\u001b[39G32000000 lines.\u001b[39G32100000 lines.\u001b[39G32200000 lines.\u001b[39G32300000 lines.\u001b[39G32400000 lines.\u001b[39G32500000 lines.\u001b[39G32600000 lines.\u001b[39G32700000 lines.\u001b[39G32800000 lines.\u001b[39G32900000 lines.\u001b[39G33000000 lines.\u001b[39G33100000 lines.\u001b[39G33200000 lines.\u001b[39G33300000 lines.\u001b[39G33400000 lines.\u001b[39G33500000 lines.\u001b[39G33600000 lines.\u001b[39G33700000 lines.\u001b[39G33800000 lines.\u001b[39G33900000 lines.\u001b[39G34000000 lines.\u001b[39G34100000 lines.\u001b[39G34200000 lines.\u001b[39G34300000 lines.\u001b[39G34400000 lines.\u001b[39G34500000 lines.\u001b[39G34600000 lines.\u001b[39G34700000 lines.\u001b[39G34800000 lines.\u001b[39G34900000 lines.\u001b[39G35000000 lines.\u001b[39G35100000 lines.\u001b[39G35200000 lines.\u001b[39G35300000 lines.\u001b[39G35400000 lines.\u001b[39G35500000 lines.\u001b[39G35600000 lines.\u001b[39G35700000 lines.\u001b[39G35800000 lines.\u001b[39G35900000 lines.\u001b[39G36000000 lines.\u001b[39G36100000 lines.\u001b[0GMerging cooccurrence files: processed 36106377 lines.\n",
            "\n",
            "$ build/shuffle -memory 4.0 -verbose 2 < cooccurrence.bin > cooccurrence.shuf.bin\n",
            "tcmalloc: large alloc 4080222208 bytes == 0x55a138d94000 @  0x7f693ecab1e7 0x55a13791faa3 0x7f693e8a8b97 0x55a13791ed8a\n",
            "SHUFFLING COOCCURRENCES\n",
            "array size: 255013683\n",
            "Shuffling by chunks: processed 0 lines.\u001b[22Gprocessed 36106377 lines.\n",
            "Wrote 1 temporary file(s).\n",
            "tcmalloc: large alloc 4080222208 bytes == 0x55a138d94000 @  0x7f693ecab1e7 0x55a13791f1ab 0x55a13792013e 0x7f693e8a8b97 0x55a13791ed8a\n",
            "Merging temp files: processed 0 lines.\u001b[31G36106377 lines.\u001b[0GMerging temp files: processed 36106377 lines.\n",
            "\n",
            "$ build/glove -save-file vectors-imdb -threads 8 -input-file cooccurrence.shuf.bin -x-max 10 -iter 15 -vector-size 50 -binary 2 -vocab-file imdb.txt -verbose 2\n",
            "TRAINING MODEL\n",
            "Read 36106377 lines.\n",
            "Initializing parameters...done.\n",
            "vector size: 50\n",
            "vocab size: 42572\n",
            "x_max: 10.000000\n",
            "alpha: 0.750000\n",
            "01/06/20 - 06:48.23AM, iter: 001, cost: 0.058207\n",
            "01/06/20 - 06:48.41AM, iter: 002, cost: 0.042677\n",
            "01/06/20 - 06:48.59AM, iter: 003, cost: 0.038338\n",
            "01/06/20 - 06:49.17AM, iter: 004, cost: 0.035439\n",
            "01/06/20 - 06:49.34AM, iter: 005, cost: 0.033647\n",
            "01/06/20 - 06:49.53AM, iter: 006, cost: 0.032492\n",
            "01/06/20 - 06:50.13AM, iter: 007, cost: 0.031679\n",
            "01/06/20 - 06:50.33AM, iter: 008, cost: 0.031058\n",
            "01/06/20 - 06:50.52AM, iter: 009, cost: 0.030568\n",
            "01/06/20 - 06:51.12AM, iter: 010, cost: 0.030167\n",
            "01/06/20 - 06:51.32AM, iter: 011, cost: 0.029838\n",
            "01/06/20 - 06:51.51AM, iter: 012, cost: 0.029557\n",
            "01/06/20 - 06:52.09AM, iter: 013, cost: 0.029315\n",
            "01/06/20 - 06:52.27AM, iter: 014, cost: 0.029108\n",
            "01/06/20 - 06:52.45AM, iter: 015, cost: 0.028924\n",
            "$ python eval/python/evaluate.py --vocab_file imdb.txt --vectors_file vectors-imdb.txt\n",
            "capital-common-countries.txt:\n",
            "ACCURACY TOP1: 10.46% (32/306)\n",
            "capital-world.txt:\n",
            "ACCURACY TOP1: 3.78% (17/450)\n",
            "currency.txt:\n",
            "ACCURACY TOP1: 0.00% (0/40)\n",
            "city-in-state.txt:\n",
            "ACCURACY TOP1: 1.02% (10/983)\n",
            "family.txt:\n",
            "ACCURACY TOP1: 36.80% (170/462)\n",
            "gram1-adjective-to-adverb.txt:\n",
            "ACCURACY TOP1: 1.71% (17/992)\n",
            "gram2-opposite.txt:\n",
            "ACCURACY TOP1: 1.54% (10/650)\n",
            "gram3-comparative.txt:\n",
            "ACCURACY TOP1: 26.20% (349/1332)\n",
            "gram4-superlative.txt:\n",
            "ACCURACY TOP1: 9.89% (92/930)\n",
            "gram5-present-participle.txt:\n",
            "ACCURACY TOP1: 19.46% (158/812)\n",
            "gram6-nationality-adjective.txt:\n",
            "ACCURACY TOP1: 8.62% (106/1229)\n",
            "gram7-past-tense.txt:\n",
            "ACCURACY TOP1: 13.96% (186/1332)\n",
            "gram8-plural.txt:\n",
            "ACCURACY TOP1: 9.09% (96/1056)\n",
            "gram9-plural-verbs.txt:\n",
            "ACCURACY TOP1: 20.63% (156/756)\n",
            "Questions seen/total: 57.97% (11330/19544)\n",
            "Semantic accuracy: 10.22%  (229/2241)\n",
            "Syntactic accuracy: 12.87%  (1170/9089)\n",
            "Total accuracy: 12.35%  (1399/11330)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}